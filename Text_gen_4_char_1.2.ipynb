{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text gen 4 char.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orestislampridis/Greek-Lyric-Generation/blob/master/Text_gen_4_char_1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM9yBPtF6VZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Bidirectional, Activation, Dropout, Dense,CuDNNLSTM, Embedding,GRU, CuDNNGRU\n",
        "from keras.callbacks import *\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FksoK8dm61HN",
        "colab_type": "text"
      },
      "source": [
        "Load the data (lyrics) from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td1YNodF6biu",
        "colab_type": "code",
        "outputId": "84a06290-69a5-49be-9a22-28aaa931d88b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4adK_Pr1oNt",
        "colab_type": "text"
      },
      "source": [
        "The form of data is raw text in a txt file. We chose not to edit the data to achieve a result closer to the reality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdj-hiiu6fA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('/content/drive/My Drive/Colab Notebooks/entexna.txt', 'r') as f: \n",
        "    \n",
        "    text = f.read()\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4LHmIUm8j3O",
        "colab_type": "text"
      },
      "source": [
        "Check the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAuLzCnn7TA6",
        "colab_type": "code",
        "outputId": "30f16914-5f0a-4b73-e09d-b5d3618243fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(repr(text[:100]))  #read the first 200 characters of doc\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Στον δρόμο έκαιγε η άσφαλτος, ο Αύγουστος μου φέρνει ζάλη, μα αυτός ακούμπησε στον ώμο μου να γείρω '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0Imjbgl6pds",
        "colab_type": "code",
        "outputId": "3aa8dd3d-49f4-4452-d59a-bc24c0156f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "n_char=len(text)\n",
        "print ('Length of text: %i characters' %n_char) #lenght=number of characters in text\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 658282 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DYMD-sR7Lu5",
        "colab_type": "code",
        "outputId": "073b0038-96a6-49c8-b344-b01b2fc099ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab=sorted(set(text)) #making the vocabulary of characters\n",
        "n_vocab=len(vocab) \n",
        "print('number of unique characters: %i' %n_vocab)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of unique characters: 103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uminZK_z8gfx",
        "colab_type": "text"
      },
      "source": [
        "We need to map chars to numbers. Neural Networks work best with integer instead of plain text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKwsnU9y70xO",
        "colab_type": "code",
        "outputId": "5b288900-d3cc-4941-80a3-458c5e284570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "char2int=dict((i, c) for c, i in enumerate(vocab)) #map characters to int\n",
        "int2char=dict((i, c) for i, c in enumerate(vocab)) #map int to char (for \"translation\")\n",
        "\n",
        "print(char2int) #print the result of mapping the characters in the vocabulary\n",
        "print(int2char)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, ',': 3, '.': 4, '0': 5, '1': 6, '2': 7, '3': 8, '4': 9, '5': 10, '6': 11, '7': 12, '8': 13, '9': 14, ';': 15, 'Ά': 16, 'Έ': 17, 'Ή': 18, 'Ί': 19, 'Ό': 20, 'Ύ': 21, 'Ώ': 22, 'ΐ': 23, 'Α': 24, 'Β': 25, 'Γ': 26, 'Δ': 27, 'Ε': 28, 'Ζ': 29, 'Η': 30, 'Θ': 31, 'Ι': 32, 'Κ': 33, 'Λ': 34, 'Μ': 35, 'Ν': 36, 'Ξ': 37, 'Ο': 38, 'Π': 39, 'Ρ': 40, 'Σ': 41, 'Τ': 42, 'Υ': 43, 'Φ': 44, 'Χ': 45, 'Ψ': 46, 'Ω': 47, 'ά': 48, 'έ': 49, 'ή': 50, 'ί': 51, 'α': 52, 'β': 53, 'γ': 54, 'δ': 55, 'ε': 56, 'ζ': 57, 'η': 58, 'θ': 59, 'ι': 60, 'κ': 61, 'λ': 62, 'μ': 63, 'ν': 64, 'ξ': 65, 'ο': 66, 'π': 67, 'ρ': 68, 'ς': 69, 'σ': 70, 'τ': 71, 'υ': 72, 'φ': 73, 'χ': 74, 'ψ': 75, 'ω': 76, 'ϊ': 77, 'ϋ': 78, 'ό': 79, 'ύ': 80, 'ώ': 81, 'ἀ': 82, 'ἁ': 83, 'ἆ': 84, 'Ἀ': 85, 'ἐ': 86, 'ἕ': 87, 'Ἐ': 88, 'ἡ': 89, 'ἶ': 90, 'ὁ': 91, 'ὅ': 92, 'ὐ': 93, 'ὰ': 94, 'ὲ': 95, 'ὴ': 96, 'ὶ': 97, 'ὸ': 98, 'ὺ': 99, 'ᾶ': 100, 'ῖ': 101, 'ῦ': 102}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: ',', 4: '.', 5: '0', 6: '1', 7: '2', 8: '3', 9: '4', 10: '5', 11: '6', 12: '7', 13: '8', 14: '9', 15: ';', 16: 'Ά', 17: 'Έ', 18: 'Ή', 19: 'Ί', 20: 'Ό', 21: 'Ύ', 22: 'Ώ', 23: 'ΐ', 24: 'Α', 25: 'Β', 26: 'Γ', 27: 'Δ', 28: 'Ε', 29: 'Ζ', 30: 'Η', 31: 'Θ', 32: 'Ι', 33: 'Κ', 34: 'Λ', 35: 'Μ', 36: 'Ν', 37: 'Ξ', 38: 'Ο', 39: 'Π', 40: 'Ρ', 41: 'Σ', 42: 'Τ', 43: 'Υ', 44: 'Φ', 45: 'Χ', 46: 'Ψ', 47: 'Ω', 48: 'ά', 49: 'έ', 50: 'ή', 51: 'ί', 52: 'α', 53: 'β', 54: 'γ', 55: 'δ', 56: 'ε', 57: 'ζ', 58: 'η', 59: 'θ', 60: 'ι', 61: 'κ', 62: 'λ', 63: 'μ', 64: 'ν', 65: 'ξ', 66: 'ο', 67: 'π', 68: 'ρ', 69: 'ς', 70: 'σ', 71: 'τ', 72: 'υ', 73: 'φ', 74: 'χ', 75: 'ψ', 76: 'ω', 77: 'ϊ', 78: 'ϋ', 79: 'ό', 80: 'ύ', 81: 'ώ', 82: 'ἀ', 83: 'ἁ', 84: 'ἆ', 85: 'Ἀ', 86: 'ἐ', 87: 'ἕ', 88: 'Ἐ', 89: 'ἡ', 90: 'ἶ', 91: 'ὁ', 92: 'ὅ', 93: 'ὐ', 94: 'ὰ', 95: 'ὲ', 96: 'ὴ', 97: 'ὶ', 98: 'ὸ', 99: 'ὺ', 100: 'ᾶ', 101: 'ῖ', 102: 'ῦ'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJBrY-vC3Y2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_as_int=np.array([char2int[c] for c in text]) #map the data as int"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGUGCZCA9ain",
        "colab_type": "code",
        "outputId": "448bc809-3f7c-47aa-c790-43d25ccf2a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Show a sample of our data mapped from text to integers\n",
        "print ('%s --[chars to int] -- > %s' %(repr(text[100:119]), text_as_int[100:119]))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'πάνω το κεφάλι. Να ' --[chars to int] -- > [67 48 64 76  1 71 66  1 61 56 73 48 62 60  4  1 36 52  1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h3h5cNB_A8J",
        "colab_type": "text"
      },
      "source": [
        "To feed the NN we need to devide the text \n",
        "into samples(sequences).\n",
        "\n",
        "Also we devide out data to input and target\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Zmvuy3-Qgt",
        "colab_type": "code",
        "outputId": "b42c0188-f348-42fd-a132-b4ab578458bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "print('Making samples(sequences) and deviding data to input and target...\\n')\n",
        "seq_length = 100 #how many characters per sequence\n",
        "#i.e seq_length=3 text=καλή, input=καλ, target=ή\n",
        "target=[]\n",
        "input=[]\n",
        "step=5 #this step determines how many sequences we want\n",
        "for i in range (0,n_char-seq_length,step):\n",
        "\n",
        "  input.append(text_as_int[i:i+seq_length]) \n",
        "  target.append(text_as_int[i+seq_length])\n",
        "\n",
        "print('Input and target data example:')\n",
        "print(\"input 2:\", \"\".join([int2char[c] for c in input[2]]))\n",
        "print(\"target 2:\", int2char[target[2]])\n",
        "\n",
        "\n",
        "n_samples=len(input)\n",
        "print(\"\\nNumber of samples:\",n_samples)\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making samples(sequences) and deviding data to input and target...\n",
            "\n",
            "Input and target data example:\n",
            "input 2:  έκαιγε η άσφαλτος, ο Αύγουστος μου φέρνει ζάλη, μα αυτός ακούμπησε στον ώμο μου να γείρω πάνω το κε\n",
            "target 2: φ\n",
            "\n",
            "Number of samples: 131637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "evGYGkX7xnX0"
      },
      "source": [
        "We need to reshape the sequences to go into the RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qcTdFDapDZs3",
        "outputId": "e315a336-bee3-4fa7-8398-fe301efbcbc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "#We can use the reshape() function on the NumPy array to reshape this one-dimensional array into a three-dimensional array \n",
        "#with the number of samples and length we need at each time step.\n",
        "inputR=np.reshape(input,(n_samples, seq_length))\n",
        "print(\"The input representation of: \", \"\".join([int2char[c] for c in input[0][:13]]),\"is now:\")\n",
        "print(inputR[0][:13])\n",
        "#We can represent the target variables as binary vectors with One Hot Encoding.\n",
        "#\"This way me can give RNN a more expressive power to learn a probability-like number for each possible label value. \n",
        "#This can help in both making the problem easier for the network to model. \n",
        "#When a one hot encoding is used for the output variable, it may offer a more nuanced set of predictions than a single label.\"\n",
        "targetE= np_utils.to_categorical(target)\n",
        "print(\"The target representation of: \",int2char[target[60]],\" is now:\\n\",targetE[60])\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input representation of:  Στον δρόμο έκ is now:\n",
            "[41 71 66 64  1 55 68 79 63 66  1 49 61]\n",
            "The target representation of:  έ  is now:\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6bfi-ySJDYKn",
        "colab": {}
      },
      "source": [
        "#an other way of reshaping\n",
        "# inputR = np.zeros((n_samples, seq_length, n_vocab), dtype=np.bool)\n",
        "# targetE = np.zeros((n_samples, n_vocab), dtype=np.bool)\n",
        "# for i, sentence in enumerate(input):\n",
        "#     for t, char in enumerate(sentence):\n",
        "#         inputR[i, t, char] = 1\n",
        "        \n",
        "#     targetE[i, target[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M69ejzQw1Btm",
        "colab_type": "code",
        "outputId": "04d1c87e-f0ec-4cc3-e0a1-004c8357ca70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(\"the shape of the input data is:\",inputR.shape)\n",
        "print(\"the shape of the target data is:\",targetE.shape)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the shape of the input data is: (131637, 100)\n",
            "the shape of the target data is: (131637, 102)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JPqSPgMhUca",
        "colab_type": "text"
      },
      "source": [
        "**Building the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p2fdqcyhwu0",
        "colab_type": "text"
      },
      "source": [
        "We will use an Sequential LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM8z_8i5hmSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model= Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fjk_HPChkDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_size=512\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcY-rTgvaztI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Embedding(n_samples, seq_length,input_length=seq_length, trainable=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLR23-eejYwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input layer\n",
        "model.add(Bidirectional( CuDNNLSTM(rnn_size, return_sequences=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywdMeMw5l4rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hidden layers \n",
        "model.add(Bidirectional( CuDNNLSTM(rnn_size)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d152iV2zeWA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dropout layer(avoid overfitting)\n",
        "model.add(Dropout(0.2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zkw6zFjmVqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Output layer\n",
        "model.add(Dense(targetE.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlIXCekqpkSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Activation function\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEh9ITYi68eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = Adam(lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBci1wxNpoSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile model\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z1CNmMep4r8",
        "colab_type": "code",
        "outputId": "f77258fc-e256-436c-84db-5654b23d2dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "#model details\n",
        "model.summary()"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 100, 100)          13163700  \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 100, 1024)         2514944   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 1024)              6299648   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 102)               104550    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 102)               0         \n",
            "=================================================================\n",
            "Total params: 22,082,842\n",
            "Trainable params: 22,082,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xSBz89irfMb",
        "colab_type": "text"
      },
      "source": [
        "***(Callbacks)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGeEpA4QqCIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"/content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:{epoch:03d}-val_acc:{val_acc:.5f}.hdf5\"\n",
        "# folder called CheckpointsLyricsGen in drive\n",
        "#each file will be stored with epoch number and validation accuracy\n",
        "#these files contain weights of your neural network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61efQcZsPv2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose = 1, save_best_only = False, mode ='max')\n",
        "#the arguments passed in the above code it is monitoring validation accuracy \n",
        "#it stores when a higher validation accuracy is achieved than the last checkpoint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo1Y6HkbP2tY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks_list = [checkpoint]\n",
        "#a list so that you can append any other callbacks to this list and pass it in fit function while training \n",
        "#all the methods in the list will be called after every epoch\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTDIuZTh2L9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UyVzlszrmFk",
        "colab_type": "text"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovKx-ZkBrpzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if we need to train more: uncomment the code below with the correct checkpoint \n",
        "\n",
        "#model.load_weights('/content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:011-val_acc:0.49730.hdf5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L6s4MrP9cBL",
        "colab_type": "code",
        "outputId": "3391e30d-0c36-4487-da16-3d614f83df64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Training model...')"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT_GdvW6r-Nz",
        "colab_type": "code",
        "outputId": "ccec6424-29a1-447e-b6d1-199397383970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        }
      },
      "source": [
        "#fit the model\n",
        "model.fit(inputR,\n",
        "          targetE,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          shuffle= True,\n",
        "          initial_epoch=0,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_split = 0.2,\n",
        "          validation_data = None,\n",
        "          validation_steps = None)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 105309 samples, validate on 26328 samples\n",
            "Epoch 1/20\n",
            "105309/105309 [==============================] - 134s 1ms/step - loss: 2.4668 - acc: 0.3068 - val_loss: 2.0883 - val_acc: 0.3788\n",
            "\n",
            "Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:001-val_acc:0.37880.hdf5\n",
            "Epoch 2/20\n",
            "105309/105309 [==============================] - 133s 1ms/step - loss: 1.9503 - acc: 0.4179 - val_loss: 1.8356 - val_acc: 0.4536\n",
            "\n",
            "Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:002-val_acc:0.45359.hdf5\n",
            "Epoch 3/20\n",
            "105309/105309 [==============================] - 133s 1ms/step - loss: 1.7353 - acc: 0.4760 - val_loss: 1.7261 - val_acc: 0.4826\n",
            "\n",
            "Epoch 00003: saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:003-val_acc:0.48264.hdf5\n",
            "Epoch 4/20\n",
            "105309/105309 [==============================] - 133s 1ms/step - loss: 1.5771 - acc: 0.5178 - val_loss: 1.6660 - val_acc: 0.5047\n",
            "\n",
            "Epoch 00004: saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:004-val_acc:0.50471.hdf5\n",
            "Epoch 5/20\n",
            "105309/105309 [==============================] - 132s 1ms/step - loss: 1.4329 - acc: 0.5559 - val_loss: 1.6558 - val_acc: 0.5113\n",
            "\n",
            "Epoch 00005: saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:005-val_acc:0.51128.hdf5\n",
            "Epoch 6/20\n",
            "105309/105309 [==============================] - 132s 1ms/step - loss: 1.2840 - acc: 0.6001 - val_loss: 1.6787 - val_acc: 0.5119\n",
            "\n",
            "Epoch 00006: saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:006-val_acc:0.51193.hdf5\n",
            "Epoch 7/20\n",
            "105309/105309 [==============================] - 133s 1ms/step - loss: 1.1263 - acc: 0.6474 - val_loss: 1.7355 - val_acc: 0.5069\n",
            "\n",
            "Epoch 00007: saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:007-val_acc:0.50687.hdf5\n",
            "Epoch 8/20\n",
            "105309/105309 [==============================] - 133s 1ms/step - loss: 0.9671 - acc: 0.6968 - val_loss: 1.8316 - val_acc: 0.4994\n",
            "\n",
            "Epoch 00008: saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:008-val_acc:0.49939.hdf5\n",
            "Epoch 9/20\n",
            " 13568/105309 [==>...........................] - ETA: 1:46 - loss: 0.7461 - acc: 0.7702"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-140-d6a8b6e58603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m           validation_steps = None)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBoQPi8ebh9-",
        "colab_type": "text"
      },
      "source": [
        "Load weights for generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooZKAk91bhaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Load weights                                                                         #choose the right filename\n",
        "model.load_weights('/content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:008-val_acc:0.49939.hdf5')                                                                                    \n",
        "#compile model                                                                       \n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkbrvZ_T5E3n",
        "colab_type": "text"
      },
      "source": [
        "Lyrics Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQMUCc_36aqJ",
        "colab_type": "code",
        "outputId": "d1a188a1-e57d-4faf-eb5b-d7c87626cf0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# set a random seed :\n",
        "start = np.random.randint(0, len(input)-1)\n",
        "random_pattern = input[start] \n",
        "\n",
        "\n",
        "#set a not random seed\n",
        "seed=\"Η Άννα\"\n",
        "seed_int=([char2int[c] for c in seed])\n",
        "pad_len=seq_length-len(seed_int)   \n",
        "set_pattern=np.pad(seed_int,(pad_len,0),constant_values=char2int[\" \"]) #we need to pad the seed so it can be the correct shape\n",
        "\n",
        "pattern = set_pattern   #Choose what type of seed we want\n",
        "\n",
        "# if pattern.all() == set_pattern.all():\n",
        "print('Seed : ')\n",
        "print(seed)\n",
        "# elif pattern.all() == random_pattern.all():\n",
        "# print('Seed : ')\n",
        "# print(\"\\\"\",''.join([int2char[v] for v in random_pattern]), \"\\\"\\n\")\n",
        "# else:\n",
        "#   print(\"No seed\")\n",
        "\n",
        "\n",
        "\n",
        "# How many characters you want to generate\n",
        "generated_characters = 300\n",
        "\n",
        "results=[]\n",
        "\n",
        "for i in range(generated_characters):\n",
        "    x = np.reshape(pattern, ( 1, len(pattern)))\n",
        "    \n",
        "    prediction = model.predict(x,verbose = 0)\n",
        "        \n",
        "    index = np.argmax(prediction)\n",
        "\n",
        "    result = int2char[index]\n",
        "\n",
        "    results.append(result)\n",
        "    # sys.stdout.write(result)\n",
        "    \n",
        "    pattern = np.append(pattern,index)\n",
        "    \n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print(\"Generated text:\")\n",
        "print(\"\\\"\",''.join(results), \"\\\"\\n\")    \n",
        "print('\\nDone')"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed : \n",
            "Η Άννα\n",
            "Generated text:\n",
            "\"  μακριά και με παίρνεις με το φως το φως το φεγγάρι σου και με παγούδες μου είσαι εσύ που το αίμα και με το φως το παραθείο και το φως το φεγγάρι σου το παραμό που σου το παραπάνε. Πάντα μου είπες που το αίμα και μου λέξεις το φως μου το παραθάκι το φως το χρώμα της καρδιάς σου με το φως το φεγγάρι  \"\n",
            "\n",
            "\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Sz535_6Crp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YLCFR9I6Eqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5VzgSCpiIEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}