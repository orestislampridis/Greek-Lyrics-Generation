{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text gen 4 char.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orestislampridis/Greek-Lyric-Generation/blob/master/Text_gen_4_char.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM9yBPtF6VZT",
        "colab_type": "code",
        "outputId": "56d2e54c-f0ce-4a0d-b75f-5730ca243a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Bidirectional, Activation, Dropout, Dense,CuDNNLSTM, Embedding\n",
        "from keras.callbacks import *\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FksoK8dm61HN",
        "colab_type": "text"
      },
      "source": [
        "Load the data (lyrics) from google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td1YNodF6biu",
        "colab_type": "code",
        "outputId": "aac97b98-7afc-4b02-b4a1-196ab606acc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4adK_Pr1oNt",
        "colab_type": "text"
      },
      "source": [
        "The form of data is raw text in a txt file. We chose not to edit the data to achieve a result closer to the reality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdj-hiiu6fA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('/content/drive/My Drive/Colab Notebooks/lyrics entexnoi raw.txt', 'r') as f: \n",
        "    \n",
        "    text = f.read()\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LOMeCy4a8orf",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKcLrPd_JPSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=text.replace('\\ufeff',\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4LHmIUm8j3O",
        "colab_type": "text"
      },
      "source": [
        "Check the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAuLzCnn7TA6",
        "colab_type": "code",
        "outputId": "42984f73-a91d-4bd7-cef1-37a49fbb4b8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(repr(text[:100]))  #read the first 200 characters of doc\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Τώρα τι κλαις τι άλλο θες το μάθαμε κι οι δυο μας ψάξε και βρες σκύψε και δες πια δύναμη μας χώρισε '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0Imjbgl6pds",
        "colab_type": "code",
        "outputId": "c4725bc6-9a52-427d-cd45-23e13c768ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "n_char=len(text)\n",
        "print ('Length of text: %i characters' %n_char) #lenght=number of characters in text\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 741237 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DYMD-sR7Lu5",
        "colab_type": "code",
        "outputId": "1b2c2cbc-ffe1-460e-b7d8-5eeb95dfd4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab=sorted(set(text)) #making the vocabulary of characters\n",
        "n_vocab=len(vocab) \n",
        "print('number of unique characters: %i' %n_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of unique characters: 133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uminZK_z8gfx",
        "colab_type": "text"
      },
      "source": [
        "We need to map chars to numbers. Neural Networks work best with integer instead of plain text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKwsnU9y70xO",
        "colab_type": "code",
        "outputId": "2ca631fc-92b9-4ed4-f9b1-a3bd3b343a3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "char2int=dict((i, c) for c, i in enumerate(vocab)) #map characters to int\n",
        "int2char=dict((i, c) for i, c in enumerate(vocab)) #map int to char (for \"translation\")\n",
        "\n",
        "print(char2int) #print the result of mapping the characters in the vocabulary\n",
        "print(int2char)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, ',': 5, '.': 6, '0': 7, '1': 8, '2': 9, '3': 10, '4': 11, '5': 12, '6': 13, '7': 14, '8': 15, '9': 16, ':': 17, ';': 18, '?': 19, 'A': 20, 'B': 21, 'C': 22, 'D': 23, 'E': 24, 'F': 25, 'G': 26, 'H': 27, 'I': 28, 'J': 29, 'K': 30, 'L': 31, 'M': 32, 'N': 33, 'O': 34, 'P': 35, 'Q': 36, 'R': 37, 'S': 38, 'T': 39, 'X': 40, 'a': 41, 'b': 42, 'c': 43, 'd': 44, 'e': 45, 'f': 46, 'g': 47, 'h': 48, 'i': 49, 'j': 50, 'k': 51, 'l': 52, 'm': 53, 'n': 54, 'o': 55, 'p': 56, 'q': 57, 'r': 58, 's': 59, 't': 60, 'u': 61, 'v': 62, 'w': 63, 'y': 64, 'z': 65, 'µ': 66, 'Ά': 67, 'Έ': 68, 'Ή': 69, 'Ί': 70, 'Ό': 71, 'Ύ': 72, 'Ώ': 73, 'ΐ': 74, 'Α': 75, 'Β': 76, 'Γ': 77, 'Δ': 78, 'Ε': 79, 'Ζ': 80, 'Η': 81, 'Θ': 82, 'Ι': 83, 'Κ': 84, 'Λ': 85, 'Μ': 86, 'Ν': 87, 'Ξ': 88, 'Ο': 89, 'Π': 90, 'Ρ': 91, 'Σ': 92, 'Τ': 93, 'Υ': 94, 'Φ': 95, 'Χ': 96, 'Ψ': 97, 'Ω': 98, 'ά': 99, 'έ': 100, 'ή': 101, 'ί': 102, 'α': 103, 'β': 104, 'γ': 105, 'δ': 106, 'ε': 107, 'ζ': 108, 'η': 109, 'θ': 110, 'ι': 111, 'κ': 112, 'λ': 113, 'μ': 114, 'ν': 115, 'ξ': 116, 'ο': 117, 'π': 118, 'ρ': 119, 'ς': 120, 'σ': 121, 'τ': 122, 'υ': 123, 'φ': 124, 'χ': 125, 'ψ': 126, 'ω': 127, 'ϊ': 128, 'ϋ': 129, 'ό': 130, 'ύ': 131, 'ώ': 132}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: \"'\", 5: ',', 6: '.', 7: '0', 8: '1', 9: '2', 10: '3', 11: '4', 12: '5', 13: '6', 14: '7', 15: '8', 16: '9', 17: ':', 18: ';', 19: '?', 20: 'A', 21: 'B', 22: 'C', 23: 'D', 24: 'E', 25: 'F', 26: 'G', 27: 'H', 28: 'I', 29: 'J', 30: 'K', 31: 'L', 32: 'M', 33: 'N', 34: 'O', 35: 'P', 36: 'Q', 37: 'R', 38: 'S', 39: 'T', 40: 'X', 41: 'a', 42: 'b', 43: 'c', 44: 'd', 45: 'e', 46: 'f', 47: 'g', 48: 'h', 49: 'i', 50: 'j', 51: 'k', 52: 'l', 53: 'm', 54: 'n', 55: 'o', 56: 'p', 57: 'q', 58: 'r', 59: 's', 60: 't', 61: 'u', 62: 'v', 63: 'w', 64: 'y', 65: 'z', 66: 'µ', 67: 'Ά', 68: 'Έ', 69: 'Ή', 70: 'Ί', 71: 'Ό', 72: 'Ύ', 73: 'Ώ', 74: 'ΐ', 75: 'Α', 76: 'Β', 77: 'Γ', 78: 'Δ', 79: 'Ε', 80: 'Ζ', 81: 'Η', 82: 'Θ', 83: 'Ι', 84: 'Κ', 85: 'Λ', 86: 'Μ', 87: 'Ν', 88: 'Ξ', 89: 'Ο', 90: 'Π', 91: 'Ρ', 92: 'Σ', 93: 'Τ', 94: 'Υ', 95: 'Φ', 96: 'Χ', 97: 'Ψ', 98: 'Ω', 99: 'ά', 100: 'έ', 101: 'ή', 102: 'ί', 103: 'α', 104: 'β', 105: 'γ', 106: 'δ', 107: 'ε', 108: 'ζ', 109: 'η', 110: 'θ', 111: 'ι', 112: 'κ', 113: 'λ', 114: 'μ', 115: 'ν', 116: 'ξ', 117: 'ο', 118: 'π', 119: 'ρ', 120: 'ς', 121: 'σ', 122: 'τ', 123: 'υ', 124: 'φ', 125: 'χ', 126: 'ψ', 127: 'ω', 128: 'ϊ', 129: 'ϋ', 130: 'ό', 131: 'ύ', 132: 'ώ'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJBrY-vC3Y2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_as_int=np.array([char2int[c] for c in text]) #map the data as int"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGUGCZCA9ain",
        "colab_type": "code",
        "outputId": "9cc7b66c-d476-4c05-e55a-e44fc4db655f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Show a sample of our data mapped from text to integers\n",
        "print ('%s --[chars to int] -- > %s' %(repr(text[101:120]), text_as_int[101:120]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'σύ λοιπόν δε φταις ' --[chars to int] -- > [121 131   1 113 117 111 118 130 115   1 106 107   1 124 122 103 111 120\n",
            "   1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h3h5cNB_A8J",
        "colab_type": "text"
      },
      "source": [
        "To feed the NN we need to devide the text \n",
        "into samples(sequences).\n",
        "\n",
        "Also we devide out data to input and target\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Zmvuy3-Qgt",
        "colab_type": "code",
        "outputId": "656c1305-7cb0-4da7-d292-16009167b3c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "print('Making samples(sequences) and deviding data to input and target...\\n')\n",
        "seq_length = 100 #how many characters per sequence\n",
        "#i.e seq_length=3 text=καλή, input=καλ, target=ή\n",
        "target=[]\n",
        "input=[]\n",
        "step=5 #this step determines how many sequences we want\n",
        "for i in range (0,n_char-seq_length,step):\n",
        "\n",
        "  input.append(text_as_int[i:i+seq_length]) \n",
        "  target.append(text_as_int[i+seq_length])\n",
        "\n",
        "print('Input and target data example:')\n",
        "print(\"input 49:\", \"\".join([int2char[c] for c in input[49]]))\n",
        "print(\"target 49:\", int2char[target[49]])\n",
        "\n",
        "\n",
        "n_samples=len(input)\n",
        "print(\"\\nNumber of samples:\",n_samples)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making samples(sequences) and deviding data to input and target...\n",
            "\n",
            "Input and target data example:\n",
            "input 49:  γιατί μη με ρωτήσεις το 'χω νιώσει όταν πονώ σαν θα γίνεσαι ένας ξένος πιο βαθιά να σ' αγαπώ έλα μη\n",
            "target 49: ν\n",
            "\n",
            "Number of samples: 148228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYj0CpiDlD7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZrxAg1ekfTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "evGYGkX7xnX0"
      },
      "source": [
        "We need to reshape the sequences to go into the RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQ5U0MyODUIJ",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qcTdFDapDZs3",
        "outputId": "acd1396d-29bf-4d94-d918-432cce099684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "#We can use the reshape() function on the NumPy array to reshape this one-dimensional array into a three-dimensional array \n",
        "#with the number of samples, time steps, and features we need at each time step.)inputR=np.reshape(input,(n_samples, seq_length,1)\n",
        "inputR=np.reshape(input,(n_samples, seq_length))\n",
        "print(\"The input representation of: \", \"\".join([int2char[c] for c in input[0][:13]]),\"is now:\")\n",
        "print(inputR[0][:13])\n",
        "#We can represent the target variables as binary vectors with One Hot Encoding.\n",
        "#\"This way me can give RNN a more expressive power to learn a probability-like number for each possible label value. \n",
        "#This can help in both making the problem easier for the network to model. \n",
        "#When a one hot encoding is used for the output variable, it may offer a more nuanced set of predictions than a single label.\"\n",
        "targetE= np_utils.to_categorical(target)\n",
        "print(\"The target representation of: \",int2char[target[70]],\" is now:\\n\",targetE[70])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The input representation of:  Τώρα τι κλαις is now:\n",
            "[ 93 132 119 103   1 122 111   1 112 113 103 111 120]\n",
            "The target representation of:  ι  is now:\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7-c9vxGHXzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6bfi-ySJDYKn",
        "colab": {}
      },
      "source": [
        "#an other way of reshaping\n",
        "# inputR = np.zeros((n_samples, seq_length, n_vocab), dtype=np.bool)\n",
        "# targetE = np.zeros((n_samples, n_vocab), dtype=np.bool)\n",
        "# for i, sentence in enumerate(input):\n",
        "#     for t, char in enumerate(sentence):\n",
        "#         inputR[i, t, char] = 1\n",
        "        \n",
        "#     targetE[i, target[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7CCpIvEzDXBv",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M69ejzQw1Btm",
        "colab_type": "code",
        "outputId": "98a634b3-9970-4b88-b124-3889cde1ae41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(\"the shape of the input data is:\",inputR.shape)\n",
        "print(\"the shape of the target data is:\",targetE.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the shape of the input data is: (148228, 100)\n",
            "the shape of the target data is: (148228, 133)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JPqSPgMhUca",
        "colab_type": "text"
      },
      "source": [
        "**Building the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p2fdqcyhwu0",
        "colab_type": "text"
      },
      "source": [
        "We will use an Sequential LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM8z_8i5hmSX",
        "colab_type": "code",
        "outputId": "18b1b1f7-0a60-4233-9f3d-f1ae1bdc333d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "model= Sequential()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fjk_HPChkDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_size=512\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcY-rTgvaztI",
        "colab_type": "code",
        "outputId": "b5341f3f-39b6-4325-b77c-ccbabc30b823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "model.add(Embedding(n_samples, seq_length,input_length=seq_length))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLR23-eejYwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input layer\n",
        "model.add(Bidirectional( CuDNNLSTM(rnn_size)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywdMeMw5l4rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hidden layers \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d152iV2zeWA7",
        "colab_type": "code",
        "outputId": "b7fdb1a4-cefe-46b9-d074-992c055dd02c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "#Dropout layer(avoid overfitting)\n",
        "model.add(Dropout(0.3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zkw6zFjmVqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Output layer\n",
        "model.add(Dense(targetE.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlIXCekqpkSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Activation function\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBDN_OfxElX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBci1wxNpoSm",
        "colab_type": "code",
        "outputId": "82dd5f1e-8d38-4f8c-8ca4-57084c2524f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "#compile model\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z1CNmMep4r8",
        "colab_type": "code",
        "outputId": "05e27a72-bc0c-42c5-fb51-5ec8f189addd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "source": [
        "#model details\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 100)          14822800  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 1024)              2514944   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 133)               136325    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 133)               0         \n",
            "=================================================================\n",
            "Total params: 17,474,069\n",
            "Trainable params: 17,474,069\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xSBz89irfMb",
        "colab_type": "text"
      },
      "source": [
        "***(Callbacks)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGeEpA4QqCIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"/content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:{epoch:03d}-val_acc:{val_acc:.5f}.hdf5\"\n",
        "# folder called CheckpointsLyricsGen in drive\n",
        "#each file will be stored with epoch number and validation accuracy\n",
        "#these files contain weights of your neural network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61efQcZsPv2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose = 1, save_best_only = True, mode ='max')\n",
        "#the arguments passed in the above code it is monitoring validation accuracy \n",
        "#it stores when a higher validation accuracy is achieved than the last checkpoint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo1Y6HkbP2tY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks_list = [checkpoint]\n",
        "#a list so that you can append any other callbacks to this list and pass it in fit function while training \n",
        "#all the methods in the list will be called after every epoch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UyVzlszrmFk",
        "colab_type": "text"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovKx-ZkBrpzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if we need to train more: uncomment the code below with the correct checkpoint \n",
        "\n",
        "#model.load_weights('/content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:011-val_acc:0.49730.hdf5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L6s4MrP9cBL",
        "colab_type": "code",
        "outputId": "76cdbfba-89b5-49bf-ce71-ad6b2ff57bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Training model...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT_GdvW6r-Nz",
        "colab_type": "code",
        "outputId": "948c4834-1d78-4721-ebd4-33bdc3c222c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#fit the model\n",
        "model.fit(inputR,\n",
        "          targetE,\n",
        "          epochs=30,\n",
        "          batch_size=128,\n",
        "          shuffle= True,\n",
        "          initial_epoch=0,\n",
        "          callbacks=callbacks_list,\n",
        "          validation_split = 0.2,\n",
        "          validation_data = None,\n",
        "          validation_steps = None)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 118582 samples, validate on 29646 samples\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "118582/118582 [==============================] - 175s 1ms/step - loss: 2.5204 - acc: 0.3112 - val_loss: 2.1514 - val_acc: 0.3866\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.38660, saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:001-val_acc:0.38660.hdf5\n",
            "Epoch 2/30\n",
            "118582/118582 [==============================] - 172s 1ms/step - loss: 2.0178 - acc: 0.4156 - val_loss: 1.9089 - val_acc: 0.4441\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.38660 to 0.44411, saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:002-val_acc:0.44411.hdf5\n",
            "Epoch 3/30\n",
            "118582/118582 [==============================] - 173s 1ms/step - loss: 1.8156 - acc: 0.4689 - val_loss: 1.7995 - val_acc: 0.4725\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.44411 to 0.47251, saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:003-val_acc:0.47251.hdf5\n",
            "Epoch 4/30\n",
            "118582/118582 [==============================] - 173s 1ms/step - loss: 1.6807 - acc: 0.5027 - val_loss: 1.7456 - val_acc: 0.4891\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.47251 to 0.48910, saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:004-val_acc:0.48910.hdf5\n",
            "Epoch 5/30\n",
            "118582/118582 [==============================] - 173s 1ms/step - loss: 1.5689 - acc: 0.5311 - val_loss: 1.7161 - val_acc: 0.4979\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.48910 to 0.49787, saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:005-val_acc:0.49787.hdf5\n",
            "Epoch 6/30\n",
            "118582/118582 [==============================] - 173s 1ms/step - loss: 1.4696 - acc: 0.5580 - val_loss: 1.7112 - val_acc: 0.5050\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.49787 to 0.50503, saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:006-val_acc:0.50503.hdf5\n",
            "Epoch 7/30\n",
            "118582/118582 [==============================] - 173s 1ms/step - loss: 1.3713 - acc: 0.5858 - val_loss: 1.7344 - val_acc: 0.5042\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.50503\n",
            "Epoch 8/30\n",
            "118582/118582 [==============================] - 173s 1ms/step - loss: 1.2712 - acc: 0.6114 - val_loss: 1.7573 - val_acc: 0.5028\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.50503\n",
            "Epoch 9/30\n",
            "118582/118582 [==============================] - 173s 1ms/step - loss: 1.1736 - acc: 0.6386 - val_loss: 1.7980 - val_acc: 0.5061\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.50503 to 0.50607, saving model to /content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:009-val_acc:0.50607.hdf5\n",
            "Epoch 10/30\n",
            "118582/118582 [==============================] - 173s 1ms/step - loss: 1.0696 - acc: 0.6706 - val_loss: 1.8633 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.50607\n",
            "Epoch 11/30\n",
            " 47232/118582 [==========>...................] - ETA: 1:37 - loss: 0.9204 - acc: 0.7169"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBoQPi8ebh9-",
        "colab_type": "text"
      },
      "source": [
        "Load weights for generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooZKAk91bhaD",
        "colab_type": "code",
        "outputId": "268a65a8-a6b1-4a95-c640-3f2002f5bc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "\n",
        "#Load weights                                                                         #choose the right filename\n",
        "model.load_weights('/content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:006-val_acc:0.50668.hdf5')                                                                                    \n",
        "#compile model                                                                       \n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-774338252025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/CheckpointsLyricsGen/epochs:006-val_acc:0.50668.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#compile model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkbrvZ_T5E3n",
        "colab_type": "text"
      },
      "source": [
        "Lyrics Generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQMUCc_36aqJ",
        "colab_type": "code",
        "outputId": "ca57e03a-13df-4b02-f1f9-fa27f9d3ba62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "# set a random seed :\n",
        "start = np.random.randint(0, len(input)-1)\n",
        "pattern = input[start]\n",
        "print('Seed : ')\n",
        "print(\"\\\"\",''.join([int2char[v] for v in pattern]), \"\\\"\\n\")\n",
        "\n",
        "# How many characters you want to generate\n",
        "generated_characters = 300\n",
        "\n",
        "results=[]\n",
        "\n",
        "for i in range(generated_characters):\n",
        "    x = np.reshape(pattern, ( 1, len(pattern)))\n",
        "    \n",
        "    prediction = model.predict(x,verbose = 0)\n",
        "    index = np.argmax(prediction)\n",
        "\n",
        "    result = int2char[index]\n",
        "\n",
        "    results.append(result)\n",
        "    sys.stdout.write(result)\n",
        "    \n",
        "    pattern = np.append(pattern,index)\n",
        "    \n",
        "    pattern = pattern[1:len(pattern)]\n",
        "# print(\"\\\"\",''.join(results), \"\\\"\\n\")    \n",
        "print('\\nDone')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7fcfe0ad51f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Seed : '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint2char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Sz535_6Crp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YLCFR9I6Eqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5VzgSCpiIEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}